{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TruLens vs RAGAS vs MLFlow performance comparison for groundedness\n",
    "\n",
    "In this notebook, we analyze the performance of TruLens current groundedness feedback function and its comparable or equivalent implementations from other evaluation frameworks using the same model for LLM-as-judges. \n",
    "\n",
    "\n",
    "### Definitions\n",
    "1. TruLens `groundedness`: evaluates whether a response is fully supported by the source or retrieved contexts.\n",
    "\n",
    "2. RAGAS `faithfulness`: measures the factual consistency of the generated answer against the given context [source](https://docs.ragas.io/en/stable/concepts/metrics/faithfulness.html)\n",
    "\n",
    "3. MLflow `faithfulness`: Faithfulness will be assessed based on how factually consistent the output is to the context\n",
    "[source](https://mlflow.org/docs/latest/python_api/mlflow.metrics.html#mlflow.metrics.genai.faithfulness)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install trulens-core trulens-providers-openai ragas mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/trulens/lib/python3.11/site-packages/snowflake/sqlalchemy/base.py:1068: SAWarning: The GenericFunction 'flatten' is already registered and is going to be overridden.\n",
      "  functions.register_function(\"flatten\", flatten)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `TruSession` to prevent this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
      "Updating app_id in records table: 0it [00:00, ?it/s]\n",
      "Updating app_json in apps table: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from trulens.connectors.snowflake import SnowflakeConnector\n",
    "from trulens.core.session import TruSession\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "\n",
    "connection_params = {\n",
    "    \"account\": os.environ.get(\"SNOWFLAKE_ACCOUNT\"),\n",
    "    \"user\": os.environ.get(\"SNOWFLAKE_USER\"),\n",
    "    \"password\": os.environ.get(\"SNOWFLAKE_USER_PASSWORD\"),\n",
    "    \"database\": os.environ.get(\"SNOWFLAKE_DATABASE\"),\n",
    "    \"schema\": os.environ.get(\"SNOWFLAKE_SCHEMA\"),\n",
    "    \"warehouse\": os.environ.get(\"SNOWFLAKE_WAREHOUSE\"),\n",
    "    \"role\": os.environ.get(\"SNOWFLAKE_ROLE\"),\n",
    "    \"init_server_side\": False,  # Set to True to enable server side feedback functions\n",
    "}\n",
    "\n",
    "# connector = SnowflakeConnector(**connection_params)\n",
    "# session = TruSession(connector=connector)\n",
    "\n",
    "session = TruSession()\n",
    "session.reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare 3 public benchmark datasets: QAGS CNN/Daily Mail, QAGS XSum, and SummEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from trulens.benchmark.benchmark_frameworks.experiments.dataset_preprocessing import (\n",
    "    generate_qags_golden_set_groundedness,\n",
    ")\n",
    "from trulens.benchmark.benchmark_frameworks.experiments.dataset_preprocessing import (\n",
    "    generate_summeval_groundedness_golden_set,\n",
    ")\n",
    "\n",
    "qags_cnn_dm = pd.DataFrame(\n",
    "    list(generate_qags_golden_set_groundedness(\"data/qags_mturk_cnndm.jsonl\"))\n",
    ")\n",
    "\n",
    "qags_xsum = pd.DataFrame(\n",
    "    list(generate_qags_golden_set_groundedness(\"data/qags_mturk_xsum.jsonl\"))\n",
    ")\n",
    "\n",
    "summeval = pd.DataFrame(\n",
    "    list(\n",
    "        generate_summeval_groundedness_golden_set(\n",
    "            \"data/summeval_test.json\", max_samples_per_bucket=200\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "summeval_true_labels = [row[\"expected_score\"] for _, row in summeval.iterrows()]\n",
    "\n",
    "summeval_true_labels_binary = [\n",
    "    1 if label >= 0.5 else 0 for label in summeval_true_labels\n",
    "]\n",
    "\n",
    "qags_cnn_dm_true_labels = [\n",
    "    row[\"expected_score\"] for _, row in qags_cnn_dm.iterrows()\n",
    "]\n",
    "\n",
    "qags_cnn_dm_true_labels_binary = [\n",
    "    1 if label >= 0.5 else 0 for label in qags_cnn_dm_true_labels\n",
    "]\n",
    "\n",
    "qags_xsum_true_labels = [\n",
    "    row[\"expected_score\"] for _, row in qags_xsum.iterrows()\n",
    "]\n",
    "\n",
    "qags_xsum_true_labels_binary = [\n",
    "    1 if label >= 0.5 else 0 for label in qags_xsum_true_labels\n",
    "]\n",
    "combined_dataset = pd.concat(\n",
    "    [qags_cnn_dm, qags_xsum, summeval], ignore_index=False\n",
    ")\n",
    "combined_true_labels = (\n",
    "    qags_cnn_dm_true_labels + qags_xsum_true_labels + summeval_true_labels\n",
    ")\n",
    "\n",
    "assert len(combined_dataset) == len(combined_true_labels)\n",
    "print(f\"Total number of samples: {len(combined_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.benchmark.benchmark_frameworks.experiments.dataset_preprocessing import (\n",
    "    visualize_expected_score_distribution,\n",
    ")\n",
    "\n",
    "# making sure the distribution of the expected scores is as balanced as possible for the datasets\n",
    "visualize_expected_score_distribution(combined_true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup experiments with TruLens `TruBasicApp` recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core import Provider\n",
    "\n",
    "\n",
    "THRESHOLD = 0.33\n",
    "class CustomTermFeedback(Provider):\n",
    "    def true_positive(self, output: str) -> float:\n",
    "        feedback_score, gt_score = float(output.split(\";\")[0]), float(output.split(\";\")[1])\n",
    "        binary_score = 1 if feedback_score >= 0.5 else 0\n",
    "        binary_gt_score = 1 if gt_score >= THRESHOLD else 0\n",
    "        return 1.0 if binary_score == 1 and binary_gt_score == 1 else 0.0\n",
    "        \n",
    "    def true_negative(self, output: str) -> float:\n",
    "        feedback_score, gt_score = float(output.split(\";\")[0]), float(output.split(\";\")[1])\n",
    "        binary_score = 1 if feedback_score >= 0.5 else 0\n",
    "        binary_gt_score = 1 if gt_score >= THRESHOLD else 0\n",
    "        return 1.0 if binary_score == 0 and binary_gt_score == 0 else 0.0\n",
    "\n",
    "    def false_positive(self, output: str) -> float:\n",
    "        feedback_score, gt_score = float(output.split(\";\")[0]), float(output.split(\";\")[1])\n",
    "        binary_score = 1 if feedback_score >= 0.5 else 0\n",
    "        binary_gt_score = 1 if gt_score >= THRESHOLD else 0\n",
    "        return 1.0 if binary_score == 1 and binary_gt_score == 0 else 0.0\n",
    "    def false_negative(self, output: str) -> float:\n",
    "        feedback_score, gt_score = float(output.split(\";\")[0]), float(output.split(\";\")[1])\n",
    "        binary_score = 1 if feedback_score >= 0.5 else 0\n",
    "        binary_gt_score = 1 if gt_score >= THRESHOLD else 0\n",
    "        return 1.0 if binary_score == 0 and binary_gt_score == 1 else 0.0\n",
    "    \n",
    "    def term_absolute_error(self, output: str) -> float:\n",
    "        feedback_score, gt_score = float(output.split(\";\")[0]), float(output.split(\";\")[1])\n",
    "        return abs(feedback_score - gt_score)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import mlflow\n",
    "from mlflow.metrics.genai import answer_relevance as answer_relevance_mlflow\n",
    "from mlflow.metrics.genai import faithfulness as faithfulness_mlflow\n",
    "from mlflow.metrics.genai import relevance as context_relevance_mlflow\n",
    "# from ragas import evaluate\n",
    "# from ragas.cost import get_token_usage_for_openai\n",
    "# from ragas.llms import llm_factory\n",
    "# from ragas.metrics import faithfulness as faithfulness_ragas\n",
    "from trulens.apps.basic import TruBasicApp\n",
    "from trulens.core import Feedback\n",
    "from trulens.providers.openai import OpenAI\n",
    "\n",
    "OPENAI_LLM_NAME = \"gpt-4o-mini\"\n",
    "gpt_4o_mini = OpenAI(model_engine=OPENAI_LLM_NAME)\n",
    "\n",
    "\n",
    "# def trulens_groundedness(context: str, response: str, gt_score: float) -> str:\n",
    "#     trulens_groundedness_res = (\n",
    "#         gpt_4o_mini.groundedness_measure_with_cot_reasons(\n",
    "#             source=context, statement=response, use_sent_tokenize=True\n",
    "#         )\n",
    "#     )\n",
    "#     return f\"{trulens_groundedness_res[0]};{gt_score};{trulens_groundedness_res[1]}\"\n",
    "\n",
    "\n",
    "# langchain_llm = llm_factory(model=OPENAI_LLM_NAME)\n",
    "# faithfulness_ragas.llm = langchain_llm\n",
    "\n",
    "\n",
    "# def ragas_faithfulness(context: str, response: str, gt_score: float) -> str:\n",
    "#     data_samples = {\"question\": [], \"answer\": [], \"contexts\": []}\n",
    "#     data_samples[\"question\"].append(\"dummy text\")\n",
    "#     data_samples[\"answer\"].append(response)\n",
    "#     data_samples[\"contexts\"].append([context])\n",
    "#     ragas_dataset = Dataset.from_dict(data_samples)\n",
    "\n",
    "#     score_dict = evaluate(\n",
    "#         ragas_dataset,\n",
    "#         metrics=[faithfulness_ragas],\n",
    "#         llm=langchain_llm,\n",
    "#         token_usage_parser=get_token_usage_for_openai,\n",
    "#     )\n",
    "\n",
    "#     return f\"{score_dict['faithfulness'][0]};{gt_score}\"\n",
    "\n",
    "# # not supplying any example as other metrics do zero-shot evaluation as well\n",
    "# faithfulness_metric = faithfulness_mlflow(\n",
    "#     model=f\"openai:/{OPENAI_LLM_NAME}\"\n",
    "# )  \n",
    "# context_relevance_metric = context_relevance_mlflow(\n",
    "#     model=f\"openai:/{OPENAI_LLM_NAME}\"\n",
    "# )\n",
    "\n",
    "# answer_relevance_metric = answer_relevance_mlflow(\n",
    "#     model=f\"openai:/{OPENAI_LLM_NAME}\"\n",
    "# )\n",
    "\n",
    "# def mlflow_context_relevance(query: str, context: str, response: str, gt_score: float) -> str:\n",
    "#     eval_data = pd.DataFrame({\n",
    "#         \"inputs\": [\n",
    "#            query \n",
    "#         ],\n",
    "#         \"predictions\": [response], # note that we are using the response as the prediction\n",
    "#         \"context\": [context],\n",
    "#     })\n",
    "\n",
    "#     with mlflow.start_run() as _:\n",
    "#         results = mlflow.evaluate(\n",
    "#             data=eval_data,\n",
    "#             predictions=\"predictions\",\n",
    "#             extra_metrics=[context_relevance_metric\n",
    "#            ],\n",
    "#             evaluators=\"default\",\n",
    "#         )\n",
    "\n",
    "#     mlflow_context_relevance_score = results.metrics[\"relevance/v1/mean\"]\n",
    "\n",
    "#     mlflow_context_relevance_score_norm = (\n",
    "#         mlflow_context_relevance_score - 1\n",
    "#     ) / 4.0  # normalizing the score to be between 0 and 1\n",
    "\n",
    "#     return f\"{mlflow_context_relevance_score_norm};{gt_score}\"\n",
    "\n",
    "# def mlflow_answer_relevance(query: str, response: str, gt_score: float) -> str:\n",
    "#     eval_data = pd.DataFrame({\n",
    "#         \"inputs\": [query],\n",
    "#         \"predictions\": [response],\n",
    "#         \"context\": [\"dummy text\"],  # we are not using the context for answer relevance evaluation\n",
    "#     })\n",
    "\n",
    "#     with mlflow.start_run() as _:\n",
    "#         results = mlflow.evaluate(\n",
    "#             data=eval_data,\n",
    "#             predictions=\"predictions\",\n",
    "#             extra_metrics=[answer_relevance_metric],\n",
    "#             evaluators=\"default\",\n",
    "#         )\n",
    "\n",
    "#     mlflow_answer_relevance_score = results.metrics[\"answer_relevance/v1/mean\"]\n",
    "\n",
    "#     mlflow_answer_relevance_score_norm = (\n",
    "#         mlflow_answer_relevance_score - 1\n",
    "#     ) / 4.0  # normalizing the score to be between 0 and 1\n",
    "\n",
    "#     return f\"{mlflow_answer_relevance_score_norm};{gt_score}\"\n",
    "\n",
    "# def mlflow_faithfulness(context: str, response: str, gt_score: float) -> str:\n",
    "#     eval_data = pd.DataFrame({\n",
    "#         \"inputs\": [\n",
    "#             \"dummy text\"  # we are not using the inputs (user's queries) for faithfulness evaluation\n",
    "#         ],\n",
    "#         \"predictions\": [response],\n",
    "#         \"context\": [context],\n",
    "#     })\n",
    "\n",
    "#     with mlflow.start_run() as _:\n",
    "#         results = mlflow.evaluate(\n",
    "#             data=eval_data,\n",
    "#             predictions=\"predictions\",\n",
    "#             extra_metrics=[\n",
    "#                 faithfulness_metric            \n",
    "#             ],\n",
    "#             evaluators=\"default\",\n",
    "#         )\n",
    "\n",
    "#     mlflow_faithfulness_score = results.metrics[\"faithfulness/v1/mean\"]\n",
    "\n",
    "#     mlflow_faithfulness_score_norm = (\n",
    "#         mlflow_faithfulness_score - 1\n",
    "#     ) / 4.0  # normalizing the score to be between 0 and 1\n",
    "\n",
    "#     return f\"{mlflow_faithfulness_score_norm};{gt_score}\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_experiment_and_record(\n",
    "    evaluate_func_wrapper, app_name, app_version, dataset_df, true_labels\n",
    "):\n",
    "    if len(dataset_df) != len(true_labels):\n",
    "        raise ValueError(\"dataset df must have the same length as labels\")\n",
    "\n",
    "    tru_wrapped_basic_app = TruBasicApp(\n",
    "        evaluate_func_wrapper,\n",
    "        app_name=app_name,\n",
    "        app_version=app_version,\n",
    "        feedbacks=CUSTOM_FEEDBACK_FUNCS,\n",
    "    )\n",
    "\n",
    "    for i in range(len(dataset_df)):\n",
    "        arg_1 = dataset_df.iloc[i][\"query\"]\n",
    "        arg_2 = dataset_df.iloc[i][\"expected_response\"]\n",
    "        arg_3 = true_labels[i]\n",
    "\n",
    "        try:\n",
    "            with tru_wrapped_basic_app as _:\n",
    "                tru_wrapped_basic_app.app(arg_1, arg_2, arg_3)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Error {e} in run_feedback_experiment row {i} with first arg {arg_1} and second arg {arg_2}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"competitive-analysis-10312024\"\n",
    "run_experiment_and_record(\n",
    "    evaluate_func_wrapper=trulens_groundedness,\n",
    "    app_version=\"trulens-groundedness\",\n",
    "    app_name=EXP_NAME,\n",
    "    dataset_df=combined_dataset,\n",
    "    true_labels=combined_true_labels,\n",
    ")\n",
    "\n",
    "run_experiment_and_record(\n",
    "    evaluate_func_wrapper=ragas_faithfulness,\n",
    "    app_version=\"ragas-faithfulness\",\n",
    "    app_name=EXP_NAME,\n",
    "    dataset_df=combined_dataset,\n",
    "    true_labels=combined_true_labels,\n",
    ")\n",
    "\n",
    "run_experiment_and_record(\n",
    "    evaluate_func_wrapper=mlflow_faithfulness,\n",
    "    app_version=\"mlflow-faithfulness\",\n",
    "    app_name=EXP_NAME,\n",
    "    dataset_df=combined_dataset,\n",
    "    true_labels=combined_true_labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note about column name mapping: in all our dataframes (CNN/DM, XSUM, and SummEval), the \"expected_score\" column is the ground truth (true) label for the groundedness score, query corresponds to the context, and expected_response corresponds to the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLflow Answer Relevance and Contex Relevance experiments \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from trulens.benchmark.benchmark_frameworks.dataset.beir_loader import (\n",
    "    TruBEIRDataLoader,\n",
    ")\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "def generate_ms_marco_context_relevance_benchmark_for_mlflow(\n",
    "    file_path: str = \"data/ms_marco_v2_1_val.parquet\",\n",
    "):\n",
    "    df = pd.read_parquet(file_path, engine=\"pyarrow\")  # or engine='fastparquet'\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        assert len(row[\"passages\"][\"is_selected\"]) == len(\n",
    "            row[\"passages\"][\"passage_text\"]\n",
    "        )\n",
    "\n",
    "        if sum(row[\"passages\"][\"is_selected\"]) < 1:\n",
    "            # currently we only consider sample with one passage marked as relevant (there are samples where zero passage_text is selected)\n",
    "            continue\n",
    "        for i, passage_text in enumerate(row[\"passages\"][\"passage_text\"]):\n",
    "            yield {\n",
    "                \"query_id\": row[\"query_id\"],\n",
    "                \"query\": row[\"query\"],\n",
    "                \"expected_response\": row[\"answers\"][0],\n",
    "                \"expected_context\": passage_text,\n",
    "                \"expected_score\": row[\"passages\"][\"is_selected\"][\n",
    "                    i\n",
    "                ],  # Binary relevance\n",
    "            }\n",
    "\n",
    "ms_marco = list(generate_ms_marco_context_relevance_benchmark_for_mlflow(\n",
    "))\n",
    "\n",
    "\n",
    "score_1_entries = [entry for entry in ms_marco if entry[\"expected_score\"] == 1]\n",
    "score_0_entries = [entry for entry in ms_marco if entry[\"expected_score\"] == 0]\n",
    "\n",
    "# Calculate the number of samples needed from each group\n",
    "num_samples_per_group = min(\n",
    "    len(score_1_entries), len(score_0_entries), 150\n",
    ")  # Sample 150 from each\n",
    "\n",
    "\n",
    "sampled_score_1 = random.sample(score_1_entries, num_samples_per_group)\n",
    "sampled_score_0 = random.sample(score_0_entries, num_samples_per_group)\n",
    "\n",
    "# Combine and shuffle the samples to get a balanced dataset\n",
    "balanced_sample = sampled_score_1 + sampled_score_0\n",
    "random.shuffle(balanced_sample)\n",
    "\n",
    "# Ensure the combined length is 300\n",
    "assert len(balanced_sample) == 300\n",
    "\n",
    "# Now you can use `balanced_sample` as your final dataset\n",
    "print(\n",
    "    f\"Number of entries with expected_score = 1: {len([e for e in balanced_sample if e['expected_score'] == 1])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Number of entries with expected_score = 0: {len([e for e in balanced_sample if e['expected_score'] == 0])}\"\n",
    ")\n",
    "\n",
    "ms_marco_balanced_sample_300 = pd.DataFrame(balanced_sample)\n",
    "\n",
    "\n",
    "beir_data_loader = TruBEIRDataLoader(data_folder=\"./\", dataset_name=\"hotpotqa\")\n",
    "hotpotqa = beir_data_loader.load_dataset_to_df(download=True)\n",
    "\n",
    "\n",
    "hotpotqa_raw_subset = hotpotqa.sample(n=200, random_state=42)\n",
    "\n",
    "all_responses = [\n",
    "    (row[\"query\"], row[\"expected_response\"])\n",
    "    for idx, row in hotpotqa_raw_subset.iterrows()\n",
    "]\n",
    "\n",
    "\n",
    "hotpotqa_subset_for_answer_relevance = [] \n",
    "\n",
    "for idx, row in hotpotqa_raw_subset.iterrows():\n",
    "    # Positive examples for answer relevance\n",
    "    hotpotqa_subset_for_answer_relevance.append({\n",
    "        \"query\": row[\"query\"],\n",
    "        \"expected_response\": row[\"expected_response\"],  # Positive response\n",
    "        \"expected_score\": 1,  # Positive example, score = 1\n",
    "    })\n",
    "\n",
    "    # Negative examples for answer relevance (random unrelated response)\n",
    "    negative_response = random.choice([\n",
    "        r\n",
    "        for q, r in all_responses\n",
    "        if q != row[\"query\"]  # Pick response from another query\n",
    "    ])\n",
    "\n",
    "    hotpotqa_subset_for_answer_relevance.append({\n",
    "        \"query\": row[\"query\"],\n",
    "        \"expected_response\": negative_response,  # Negative response\n",
    "        \"expected_score\": 0,  # Negative example, score = 0\n",
    "    })\n",
    "\n",
    "\n",
    "hotpotqa_subset_for_answer_relevance_true_labels = [\n",
    "    entry[\"expected_score\"] for entry in hotpotqa_subset_for_answer_relevance\n",
    "]\n",
    "\n",
    "hotpotqa_subset_for_answer_relevance = pd.DataFrame(\n",
    "    hotpotqa_subset_for_answer_relevance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_marco_balanced_sample_300_true_labels = ms_marco_balanced_sample_300[\"expected_score\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotpotqa_subset_for_answer_relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_marco_balanced_sample_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
      "Updating app_id in records table: 0it [00:00, ?it/s]\n",
      "Updating app_json in apps table: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from trulens.connectors.snowflake import SnowflakeConnector\n",
    "from trulens.core.session import TruSession\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "\n",
    "\n",
    "session = TruSession()\n",
    "session.reset_database()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tru_wrapped_answer_relevance_app = TruBasicApp(\n",
    "    mlflow_answer_relevance,\n",
    "    app_name=\"competitive-analysis-mlflow-11022024\",\n",
    "    app_version=\"mlflow-answer-relevance\",\n",
    "    feedbacks=CUSTOM_FEEDBACK_FUNCS,\n",
    ")\n",
    "\n",
    "for i in range(len(hotpotqa_subset_for_answer_relevance)):\n",
    "    arg_1 = hotpotqa_subset_for_answer_relevance.iloc[i][\"query\"]\n",
    "    arg_2 = hotpotqa_subset_for_answer_relevance.iloc[i][\"expected_response\"]\n",
    "    arg_3 = hotpotqa_subset_for_answer_relevance_true_labels[i]\n",
    "\n",
    "    try:\n",
    "        with tru_wrapped_answer_relevance_app as _:\n",
    "            tru_wrapped_answer_relevance_app.app(arg_1, arg_2, arg_3)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"Error {e} in run_feedback_experiment row {i} with first arg {arg_1} and second arg {arg_2}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_marco_balanced_sample_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlflow_context_relevance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapps\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TruBasicApp\n\u001b[1;32m      3\u001b[0m tru_wrapped_answer_relevance_app \u001b[38;5;241m=\u001b[39m TruBasicApp(\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mmlflow_context_relevance\u001b[49m,\n\u001b[1;32m      5\u001b[0m     app_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompetitive-analysis-mlflow-11022024\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     app_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlflow-context-relevance\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     feedbacks\u001b[38;5;241m=\u001b[39mCUSTOM_FEEDBACK_FUNCS,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ms_marco_balanced_sample_300)):\n\u001b[1;32m     11\u001b[0m     arg_1 \u001b[38;5;241m=\u001b[39m ms_marco_balanced_sample_300\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mlflow_context_relevance' is not defined"
     ]
    }
   ],
   "source": [
    "from trulens.apps.basic import TruBasicApp\n",
    "\n",
    "tru_wrapped_answer_relevance_app = TruBasicApp(\n",
    "    mlflow_context_relevance,\n",
    "    app_name=\"competitive-analysis-mlflow-11022024\",\n",
    "    app_version=\"mlflow-context-relevance\",\n",
    "    feedbacks=CUSTOM_FEEDBACK_FUNCS,\n",
    ")\n",
    "\n",
    "for i in range(len(ms_marco_balanced_sample_300)):\n",
    "    arg_1 = ms_marco_balanced_sample_300.iloc[i][\"query\"]\n",
    "    arg_2 = ms_marco_balanced_sample_300.iloc[i][\"expected_context\"]\n",
    "    arg_3 = ms_marco_balanced_sample_300.iloc[i][\"expected_response\"]\n",
    "    arg_4 = ms_marco_balanced_sample_300_true_labels[i]\n",
    "\n",
    "    try:\n",
    "        with tru_wrapped_answer_relevance_app as _:\n",
    "            tru_wrapped_answer_relevance_app.app(arg_1, arg_2, arg_3, arg_4)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"Error {e} in run_feedback_experiment row {i} with first arg {arg_1} and second arg {arg_2} and third arg {arg_3}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.get_leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark context relevance with Python ir-datasets package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "from snowflake.snowpark.session import Session\n",
    "from trulens.providers.cortex import Cortex\n",
    "from trulens.providers.litellm import LiteLLM\n",
    "from trulens.providers.openai import OpenAI\n",
    "\n",
    "trulens_ollama_provider = LiteLLM(\n",
    "    model_engine=\"ollama/llama3.1:8b\", api_base=\"http://localhost:11434\"\n",
    ")\n",
    "\n",
    "snowpark_session = Session.builder.configs(connection_params).create()\n",
    "\n",
    "gpt_4o = OpenAI(model_engine=\"gpt-4o\")\n",
    "gpt_4o_mini = OpenAI(model_engine=\"gpt-4o-mini\")\n",
    "# snowflake_arctic = Cortex(snowpark_session, model_engine=\"snowflake-arctic\")\n",
    "# mistral_large = Cortex(snowflake.connector.connect(**connection_params), model_engine=\"mistral-large\")\n",
    "# llama3_1_8b = Cortex(snowflake.connector.connect(**connection_params), model_engine=\"llama3.1-8b\")\n",
    "\n",
    "llama3_1_8b = LiteLLM(\n",
    "    model_engine=\"ollama/llama3.1:8b\", api_base=\"http://localhost:11434\"\n",
    ")\n",
    "PROVIDERS = [gpt_4o, gpt_4o_mini, llama3_1_8b]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def trulens_context_relevance(provider, query: str, context: str, gt_score: float) -> str:\n",
    "    trulens_context_relevance_res = (\n",
    "        provider.context_relevance_with_cot_reasons(\n",
    "            question=query, context=context\n",
    "        )\n",
    "    )\n",
    "    return f\"{trulens_context_relevance_res[0]};{gt_score};{trulens_context_relevance_res[1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.benchmark.benchmark_frameworks.experiments.dataset_preprocessing import (\n",
    "    generate_ms_marco_trec_dl_annotation_benchmark,\n",
    ")\n",
    "\n",
    "trec_doc_2022 = list(generate_ms_marco_trec_dl_annotation_benchmark(dataset_path=\"msmarco-document-v2/trec-dl-2022\", max_samples_per_bucket=150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trec_doc_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_doc_2022_true_labels = [entry[\"expected_score\"] for entry in trec_doc_2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trulens.benchmark.benchmark_frameworks.experiments.dataset_preprocessing import (\n",
    "    visualize_expected_score_distribution,\n",
    ")\n",
    "\n",
    "visualize_expected_score_distribution(trec_doc_2022_true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In True Positive, input output will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In True Negative, input output will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In False Positive, input output will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In False Negative, input output will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Absolute Error, input output will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "Running provider: gpt-4o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhuang/Documents/git/trulens/src/feedback/trulens/feedback/llm_provider.py:286: UserWarning: No supporting evidence provided. Returning score only.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m provider \u001b[38;5;129;01min\u001b[39;00m PROVIDERS:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning provider: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprovider\u001b[38;5;241m.\u001b[39mmodel_engine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m     \u001b[43mrun_experiment_for_provider\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrec_doc_2022\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# with concurrent.futures.ThreadPoolExecutor() as executor:\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#     futures = [executor.submit(run_experiment_for_provider, provider, trec_doc_2022) for provider in PROVIDERS]\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#     concurrent.futures.wait(futures)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[38], line 32\u001b[0m, in \u001b[0;36mrun_experiment_for_provider\u001b[0;34m(provider, dataset_df)\u001b[0m\n\u001b[1;32m     29\u001b[0m arg_3 \u001b[38;5;241m=\u001b[39m dataset_df[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtru_wrapped_context_relevance_app\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtru_wrapped_context_relevance_app\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/git/trulens/src/core/trulens/core/app.py:1079\u001b[0m, in \u001b[0;36mApp.__exit__\u001b[0;34m(self, exc_type, exc_value, exc_tb)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;66;03m# self._reset_context_vars()\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1079\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[38], line 33\u001b[0m, in \u001b[0;36mrun_experiment_for_provider\u001b[0;34m(provider, dataset_df)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tru_wrapped_context_relevance_app \u001b[38;5;28;01mas\u001b[39;00m _:\n\u001b[0;32m---> 33\u001b[0m         \u001b[43mtru_wrapped_context_relevance_app\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in run_feedback_experiment row \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with first arg \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and second arg \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/git/trulens/src/core/trulens/apps/basic.py:37\u001b[0m, in \u001b[0;36mTruWrapperApp.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/git/trulens/src/core/trulens/core/instruments.py:926\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.tru_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m WithInstrumentCallbacks\u001b[38;5;241m.\u001b[39m_stack_contexts\u001b[38;5;241m.\u001b[39mreset(stacks_token)\n\u001b[1;32m    924\u001b[0m WithInstrumentCallbacks\u001b[38;5;241m.\u001b[39m_context_contexts\u001b[38;5;241m.\u001b[39mreset(context_token)\n\u001b[0;32m--> 926\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrewrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/git/trulens/src/core/trulens/core/instruments.py:910\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.tru_wrapper.<locals>.rewrap\u001b[0;34m(rets)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m python_utils\u001b[38;5;241m.\u001b[39mWRAP_LAZY:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ctx \u001b[38;5;129;01min\u001b[39;00m contexts:\n\u001b[0;32m--> 910\u001b[0m         rets \u001b[38;5;241m=\u001b[39m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_lazy_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m            \u001b[49m\u001b[43mon_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_call_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     update_call_info(rets, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/git/trulens/src/core/trulens/core/instruments.py:149\u001b[0m, in \u001b[0;36mWithInstrumentCallbacks.wrap_lazy_values\u001b[0;34m(self, rets, wrap, on_done, context_vars)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m python_utils\u001b[38;5;241m.\u001b[39mis_lazy(rets):\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rets\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mon_done\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/git/trulens/src/core/trulens/core/instruments.py:854\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.tru_wrapper.<locals>.update_call_info\u001b[0;34m(rets, final)\u001b[0m\n\u001b[1;32m    848\u001b[0m         cost \u001b[38;5;241m=\u001b[39m tally()  \u001b[38;5;66;03m# get updated cost\u001b[39;00m\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(stack) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m existing_record \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    851\u001b[0m         \u001b[38;5;66;03m# If this is a root call, notify app to add the completed record\u001b[39;00m\n\u001b[1;32m    852\u001b[0m         \u001b[38;5;66;03m# into its containers:\u001b[39;00m\n\u001b[0;32m--> 854\u001b[0m         records[ctx] \u001b[38;5;241m=\u001b[39m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_add_record\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m            \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43msig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mret\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mperf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_schema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPerf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_time\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexisting_record\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexisting_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfinal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "File \u001b[0;32m~/Documents/git/trulens/src/core/trulens/core/app.py:1237\u001b[0m, in \u001b[0;36mApp.on_add_record\u001b[0;34m(self, ctx, func, sig, bindings, ret, error, perf, cost, existing_record, final)\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1235\u001b[0m     \u001b[38;5;66;03m# May block on DB.\u001b[39;00m\n\u001b[1;32m   1236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_error(record\u001b[38;5;241m=\u001b[39mrecord, error\u001b[38;5;241m=\u001b[39merror)\n\u001b[0;32m-> 1237\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;66;03m# Only continue with the feedback steps if the record is final.\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m final:\n",
      "File \u001b[0;32m~/Documents/git/trulens/src/core/trulens/core/instruments.py:768\u001b[0m, in \u001b[0;36mInstrument.tracked_method_wrapper.<locals>.tru_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;66;03m# Using sig bind here so we can produce a list of key-value\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;66;03m# pairs even if positional arguments were provided.\u001b[39;00m\n\u001b[1;32m    766\u001b[0m     bindings: BoundArguments \u001b[38;5;241m=\u001b[39m sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 768\u001b[0m     rets, tally \u001b[38;5;241m=\u001b[39m \u001b[43mcore_endpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_all_costs_tally\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    773\u001b[0m     error \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m~/Documents/git/trulens/src/core/trulens/core/feedback/endpoint.py:536\u001b[0m, in \u001b[0;36mEndpoint.track_all_costs_tally\u001b[0;34m(_Endpoint__func, with_openai, with_hugs, with_litellm, with_bedrock, with_cortex, with_dummy, *args, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrack_all_costs_tally\u001b[39m(\n\u001b[1;32m    514\u001b[0m     __func: mod_asynchro_utils\u001b[38;5;241m.\u001b[39mCallableMaybeAwaitable[A, T],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    523\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[T, python_utils\u001b[38;5;241m.\u001b[39mThunk[base_schema\u001b[38;5;241m.\u001b[39mCost]]:\n\u001b[1;32m    524\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;124;03m    Track costs of all of the apis we can currently track, over the\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;124;03m    execution of thunk.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;124;03m            change after this method returns in case of Awaitable results.\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 536\u001b[0m     result, cbs \u001b[38;5;241m=\u001b[39m \u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_all_costs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m        \u001b[49m\u001b[43m__func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_openai\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_openai\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_hugs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_hugs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_litellm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_litellm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_bedrock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_bedrock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_cortex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_cortex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_dummy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_dummy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cbs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    549\u001b[0m         \u001b[38;5;66;03m# Otherwise sum returns \"0\" below.\u001b[39;00m\n\u001b[1;32m    550\u001b[0m         tally \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: base_schema\u001b[38;5;241m.\u001b[39mCost()\n",
      "File \u001b[0;32m~/Documents/git/trulens/src/core/trulens/core/feedback/endpoint.py:508\u001b[0m, in \u001b[0;36mEndpoint.track_all_costs\u001b[0;34m(_Endpoint__func, with_openai, with_hugs, with_litellm, with_bedrock, with_cortex, with_dummy, *args, **kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    500\u001b[0m             logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    501\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not initialize endpoint \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPossibly missing key(s). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 e,\n\u001b[1;32m    506\u001b[0m             )\n\u001b[0;32m--> 508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEndpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_track_costs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m__func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_endpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/git/trulens/src/core/trulens/core/feedback/endpoint.py:613\u001b[0m, in \u001b[0;36mEndpoint._track_costs\u001b[0;34m(_Endpoint__func, with_endpoints, *args, **kwargs)\u001b[0m\n\u001b[1;32m    608\u001b[0m context_vars \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    609\u001b[0m     Endpoint\u001b[38;5;241m.\u001b[39m_context_endpoints: Endpoint\u001b[38;5;241m.\u001b[39m_context_endpoints\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m    610\u001b[0m }\n\u001b[1;32m    612\u001b[0m \u001b[38;5;66;03m# Call the function.\u001b[39;00m\n\u001b[0;32m--> 613\u001b[0m result: T \u001b[38;5;241m=\u001b[39m \u001b[43m__func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrewrap\u001b[39m(result):\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m python_utils\u001b[38;5;241m.\u001b[39mis_lazy(result):\n",
      "File \u001b[0;32m~/Documents/git/trulens/src/core/trulens/apps/basic.py:34\u001b[0m, in \u001b[0;36mTruWrapperApp._call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[37], line 3\u001b[0m, in \u001b[0;36mtrulens_context_relevance\u001b[0;34m(provider, query, context, gt_score)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrulens_context_relevance\u001b[39m(provider, query: \u001b[38;5;28mstr\u001b[39m, context: \u001b[38;5;28mstr\u001b[39m, gt_score: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m      2\u001b[0m     trulens_context_relevance_res \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mprovider\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext_relevance_with_cot_reasons\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     )\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrulens_context_relevance_res[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgt_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrulens_context_relevance_res[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/git/trulens/src/feedback/trulens/feedback/llm_provider.py:428\u001b[0m, in \u001b[0;36mLLMProvider.context_relevance_with_cot_reasons\u001b[0;34m(self, question, context, criteria, min_score_val, max_score_val, temperature)\u001b[0m\n\u001b[1;32m    417\u001b[0m output_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_determine_output_space(\n\u001b[1;32m    418\u001b[0m     min_score_val, max_score_val\n\u001b[1;32m    419\u001b[0m )\n\u001b[1;32m    421\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m feedback_v2\u001b[38;5;241m.\u001b[39mContextRelevance\u001b[38;5;241m.\u001b[39mgenerate_system_prompt(\n\u001b[1;32m    422\u001b[0m     min_score\u001b[38;5;241m=\u001b[39mmin_score_val,\n\u001b[1;32m    423\u001b[0m     max_score\u001b[38;5;241m=\u001b[39mmax_score_val,\n\u001b[1;32m    424\u001b[0m     criteria\u001b[38;5;241m=\u001b[39mcriteria,\n\u001b[1;32m    425\u001b[0m     output_space\u001b[38;5;241m=\u001b[39moutput_space,\n\u001b[1;32m    426\u001b[0m )\n\u001b[0;32m--> 428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_score_and_reasons\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_score_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_score_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_score_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_score_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/git/trulens/src/feedback/trulens/feedback/llm_provider.py:217\u001b[0m, in \u001b[0;36mLLMProvider.generate_score_and_reasons\u001b[0;34m(self, system_prompt, user_prompt, min_score_val, max_score_val, temperature)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_prompt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     llm_messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_prompt})\n\u001b[0;32m--> 217\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_in_pace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_chat_completion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupporting Evidence\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[1;32m    223\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/git/trulens/src/core/trulens/core/feedback/endpoint.py:288\u001b[0m, in \u001b[0;36mEndpoint.run_in_pace\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpace_me()\n\u001b[0;32m--> 288\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/git/trulens/src/providers/openai/trulens/providers/openai/provider.py:94\u001b[0m, in \u001b[0;36mOpenAI._create_chat_completion\u001b[0;34m(self, prompt, messages, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m123\u001b[39m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m messages \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m prompt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    100\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    101\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/git/trulens/src/core/trulens/core/feedback/endpoint.py:753\u001b[0m, in \u001b[0;36mEndpoint.wrap_function.<locals>.tru_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    747\u001b[0m context_vars \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    748\u001b[0m     Endpoint\u001b[38;5;241m.\u001b[39m_context_endpoints: Endpoint\u001b[38;5;241m.\u001b[39m_context_endpoints\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m    749\u001b[0m }\n\u001b[1;32m    751\u001b[0m \u001b[38;5;66;03m# Get the result of the wrapped function:\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;66;03m# response = context_vars.run(func, *args, **kwargs)\u001b[39;00m\n\u001b[0;32m--> 753\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;66;03m# if len(Endpoint._context_endpoints.get()) == 0:\u001b[39;00m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;66;03m#    raise ValueError(\"No endpoints.\")\u001b[39;00m\n\u001b[1;32m    758\u001b[0m bindings \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(func)\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens/lib/python3.11/site-packages/openai/_utils/_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens/lib/python3.11/site-packages/openai/resources/chat/completions.py:815\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    813\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    814\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 815\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens/lib/python3.11/site-packages/openai/_base_client.py:1277\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1265\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1272\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1274\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1275\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1276\u001b[0m     )\n\u001b[0;32m-> 1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens/lib/python3.11/site-packages/openai/_base_client.py:954\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 954\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens/lib/python3.11/site-packages/openai/_base_client.py:990\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    987\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 990\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    996\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens/lib/python3.11/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens/lib/python3.11/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens/lib/python3.11/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens/lib/python3.11/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens/lib/python3.11/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    245\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens/lib/python3.11/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens/lib/python3.11/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens/lib/python3.11/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens/lib/python3.11/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens/lib/python3.11/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens/lib/python3.11/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens/lib/python3.11/ssl.py:1295\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1292\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1293\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1294\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/trulens/lib/python3.11/ssl.py:1168\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "from trulens.apps.basic import TruBasicApp\n",
    "from trulens.core import Feedback\n",
    "\n",
    "\n",
    "\n",
    "custom_term_feedback = CustomTermFeedback()\n",
    "\n",
    "f_tp = Feedback(custom_term_feedback.true_positive, name=\"True Positive\", higher_is_better=True).on_output()\n",
    "f_tn = Feedback(custom_term_feedback.true_negative, name=\"True Negative\", higher_is_better=True).on_output()\n",
    "f_fp = Feedback(custom_term_feedback.false_positive, name=\"False Positive\", higher_is_better=False).on_output()\n",
    "f_fn = Feedback(custom_term_feedback.false_negative, name=\"False Negative\", higher_is_better=False).on_output()\n",
    "f_abs_err = Feedback(custom_term_feedback.term_absolute_error, name=\"Absolute Error\", higher_is_better=False).on_output()\n",
    "\n",
    "\n",
    "CUSTOM_FEEDBACK_FUNCS = [f_tp, f_tn, f_fp, f_fn, f_abs_err]\n",
    "\n",
    "def run_experiment_for_provider(provider, dataset_df):\n",
    "    tru_wrapped_context_relevance_app = TruBasicApp(\n",
    "        trulens_context_relevance,\n",
    "        app_name=\"trec-dl-doc-2022-11102024\",\n",
    "        app_version=f\"{provider.model_engine}-context-relevance\",\n",
    "        feedbacks=CUSTOM_FEEDBACK_FUNCS,\n",
    "    )\n",
    "\n",
    "    for i in range(len(dataset_df)):\n",
    "        arg_1 = dataset_df[i][\"query\"]\n",
    "        arg_2 = dataset_df[i][\"expected_response\"]\n",
    "        arg_3 = dataset_df[i][\"expected_score\"]\n",
    "\n",
    "        try:\n",
    "            with tru_wrapped_context_relevance_app as _:\n",
    "                tru_wrapped_context_relevance_app.app(provider, arg_1, arg_2, arg_3)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Error {e} in run_feedback_experiment row {i} with first arg {arg_1} and second arg {arg_2}\"\n",
    "            )\n",
    "\n",
    "for provider in PROVIDERS:\n",
    "    print(f\"Running provider: {provider.model_engine}\")\n",
    "    run_experiment_for_provider(provider, trec_doc_2022)\n",
    "\n",
    "# with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "#     futures = [executor.submit(run_experiment_for_provider, provider, trec_doc_2022) for provider in PROVIDERS]\n",
    "#     concurrent.futures.wait(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Absolute Error</th>\n",
       "      <th>False Negative</th>\n",
       "      <th>False Positive</th>\n",
       "      <th>True Negative</th>\n",
       "      <th>True Positive</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_name</th>\n",
       "      <th>app_version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">trec-dl-doc-2022-11102024</th>\n",
       "      <th>llama3.1-8b-context-relevance</th>\n",
       "      <td>0.337483</td>\n",
       "      <td>0.454357</td>\n",
       "      <td>0.03112</td>\n",
       "      <td>0.280083</td>\n",
       "      <td>0.234440</td>\n",
       "      <td>2.859005</td>\n",
       "      <td>0.000364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-context-relevance</th>\n",
       "      <td>0.323651</td>\n",
       "      <td>0.524896</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.311203</td>\n",
       "      <td>0.163900</td>\n",
       "      <td>1.449336</td>\n",
       "      <td>0.009867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini-context-relevance</th>\n",
       "      <td>0.313278</td>\n",
       "      <td>0.468880</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.311203</td>\n",
       "      <td>0.219917</td>\n",
       "      <td>1.628651</td>\n",
       "      <td>0.000321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Absolute Error  \\\n",
       "app_name                  app_version                                     \n",
       "trec-dl-doc-2022-11102024 llama3.1-8b-context-relevance        0.337483   \n",
       "                          gpt-4o-context-relevance             0.323651   \n",
       "                          gpt-4o-mini-context-relevance        0.313278   \n",
       "\n",
       "                                                         False Negative  \\\n",
       "app_name                  app_version                                     \n",
       "trec-dl-doc-2022-11102024 llama3.1-8b-context-relevance        0.454357   \n",
       "                          gpt-4o-context-relevance             0.524896   \n",
       "                          gpt-4o-mini-context-relevance        0.468880   \n",
       "\n",
       "                                                         False Positive  \\\n",
       "app_name                  app_version                                     \n",
       "trec-dl-doc-2022-11102024 llama3.1-8b-context-relevance         0.03112   \n",
       "                          gpt-4o-context-relevance              0.00000   \n",
       "                          gpt-4o-mini-context-relevance         0.00000   \n",
       "\n",
       "                                                         True Negative  \\\n",
       "app_name                  app_version                                    \n",
       "trec-dl-doc-2022-11102024 llama3.1-8b-context-relevance       0.280083   \n",
       "                          gpt-4o-context-relevance            0.311203   \n",
       "                          gpt-4o-mini-context-relevance       0.311203   \n",
       "\n",
       "                                                         True Positive  \\\n",
       "app_name                  app_version                                    \n",
       "trec-dl-doc-2022-11102024 llama3.1-8b-context-relevance       0.234440   \n",
       "                          gpt-4o-context-relevance            0.163900   \n",
       "                          gpt-4o-mini-context-relevance       0.219917   \n",
       "\n",
       "                                                          latency  total_cost  \n",
       "app_name                  app_version                                          \n",
       "trec-dl-doc-2022-11102024 llama3.1-8b-context-relevance  2.859005    0.000364  \n",
       "                          gpt-4o-context-relevance       1.449336    0.009867  \n",
       "                          gpt-4o-mini-context-relevance  1.628651    0.000321  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
