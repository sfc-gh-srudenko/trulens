{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ❄️ Snowflake Arctic Quickstart with Cortex LLM Functions\n",
    "\n",
    "In this quickstart you will learn build and evaluate a RAG application with Snowflake Arctic.\n",
    "\n",
    "Building and evaluating RAG applications with Snowflake Arctic offers developers a unique opportunity to leverage a top-tier, enterprise-focused LLM that is both cost-effective and open-source. Arctic excels in enterprise tasks like SQL generation and coding, providing a robust foundation for developing intelligent applications with significant cost savings. [Learn more about Snowflake Arctic](https://www.snowflake.com/blog/arctic-open-efficient-foundation-language-models-snowflake/)\n",
    "\n",
    "In this example, we will use Arctic Embed (`snowflake-arctic-embed-m`) as our embedding model via HuggingFace, and Arctic, a 480B hybrid MoE LLM for both generation and as the LLM to power TruLens feedback functions. The Arctic LLM is fully-mananaged by [Cortex LLM functions](https://docs.snowflake.com/en/user-guide/snowflake-cortex/llm-functions)\n",
    "\n",
    "Note, you'll need to have an [active Snowflake account](https://signup.snowflake.com/\n",
    ") to run Cortex LLM functions from Snowflake's data warehouse.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/examples/expositional/models/snowflake_cortex/arctic_quickstart.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install trulens trulens-providers-cortex chromadb sentence-transformers snowflake-snowpark-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from snowflake.snowpark import Session\n",
    "from trulens.core.utils.keys import check_keys\n",
    "\n",
    "check_keys(\"SNOWFLAKE_ACCOUNT\", \"SNOWFLAKE_USER\", \"SNOWFLAKE_USER_PASSWORD\")\n",
    "\n",
    "\n",
    "connection_params = {\n",
    "    \"account\": os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "    \"user\": os.environ[\"SNOWFLAKE_USER\"],\n",
    "    \"password\": os.environ[\"SNOWFLAKE_USER_PASSWORD\"],\n",
    "    \"role\": os.environ.get(\"SNOWFLAKE_ROLE\", \"ENGINEER\"),\n",
    "    \"database\": os.environ.get(\"SNOWFLAKE_DATABASE\"),\n",
    "    \"schema\": os.environ.get(\"SNOWFLAKE_SCHEMA\"),\n",
    "    \"warehouse\": os.environ.get(\"SNOWFLAKE_WAREHOUSE\"),\n",
    "}\n",
    "\n",
    "\n",
    "# Create a Snowflake session\n",
    "snowflake_session = Session.builder.configs(connection_params).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data\n",
    "\n",
    "In this case, we'll just initialize some simple text in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "university_info = \"\"\"\n",
    "The University of Washington, founded in 1861 in Seattle, is a public research university\n",
    "with over 45,000 students across three campuses in Seattle, Tacoma, and Bothell.\n",
    "As the flagship institution of the six public universities in Washington state,\n",
    "UW encompasses over 500 buildings and 20 million square feet of space,\n",
    "including one of the largest library systems in the world.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vector Store\n",
    "\n",
    "Create a chromadb vector store in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"Snowflake/snowflake-arctic-embed-m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_embeddings = model.encode([university_info])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "vector_store = chroma_client.get_or_create_collection(name=\"Universities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the university_info to the embedding database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add(\n",
    "    \"uni_info\", documents=university_info, embeddings=document_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build RAG from scratch\n",
    "\n",
    "Build a custom RAG from scratch, and add TruLens custom instrumentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.custom import instrument\n",
    "from trulens.core import TruSession\n",
    "\n",
    "session = TruSession()\n",
    "session.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.cortex import Complete\n",
    "\n",
    "\n",
    "class RAG_from_scratch:\n",
    "    @instrument\n",
    "    def retrieve(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        results = vector_store.query(\n",
    "            query_embeddings=model.encode([query], prompt_name=\"query\"),\n",
    "            n_results=2,\n",
    "        )\n",
    "        return results[\"documents\"]\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        resp = Complete(model='snowflake-arctic', prompt=[{'role': 'user', 'content': 'what is 2 + 2'}], session=snowflake_session)\n",
    "        return resp\n",
    "\n",
    "        # def escape_string_for_sql(input_string):\n",
    "        #     escaped_string = input_string.replace(\"\\\\\", \"\\\\\\\\\")\n",
    "        #     escaped_string = escaped_string.replace(\"'\", \"''\")\n",
    "        #     return escaped_string\n",
    "\n",
    "        # prompt = escape_string_for_sql(f\"\"\"\n",
    "        #  We have provided context information below. \n",
    "        #     {context_str}\n",
    "        #     Given this information, please answer the question: {query}\n",
    "        # \"\"\")\n",
    "        \n",
    "        # res = snowflake_session.sql(f\"\"\"SELECT SNOWFLAKE.CORTEX.COMPLETE(\n",
    "        #     'snowflake-arctic',\n",
    "        #     [\n",
    "        #     {{'role': 'user', 'content': '{prompt}'}}\n",
    "        #     ], {{\n",
    "        #         'temperature': 0\n",
    "        #     }}\n",
    "        #     )\"\"\").collect()    \n",
    "\n",
    "        # if len(res) == 0:\n",
    "        #     return \"No response from cortex function\"\n",
    "        # completion = json.loads(res[0][0])[\"choices\"][0][\"messages\"]\n",
    "        # print(\"full response from cortex function:\")\n",
    "        # print(res)\n",
    "        # return completion\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve(query)\n",
    "        completion = self.generate_completion(query, context_str)\n",
    "        return completion\n",
    "\n",
    "\n",
    "rag = RAG_from_scratch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the new version of the function\n",
    "# import json\n",
    "# import time\n",
    "# from typing import Any, Iterator, List, Optional, Union\n",
    "\n",
    "# from requests import Response\n",
    "# from snowflake.cortex import _complete\n",
    "# from snowflake.cortex._sse_client import SSEClient\n",
    "\n",
    "\n",
    "# def _patched_return_stream_response(response: Response, deadline: Optional[float]) -> dict:\n",
    "#     client = SSEClient(response)\n",
    "#     full_content = []  # Accumulate the content here\n",
    "#     for event in client.events():\n",
    "#         if deadline is not None and time.time() > deadline:\n",
    "#             raise TimeoutError()\n",
    "#         try:\n",
    "#             message = json.loads(event.data)\n",
    "#             full_content.append(message[\"choices\"][0][\"delta\"][\"content\"])\n",
    "    \n",
    "#         except (json.JSONDecodeError, KeyError, IndexError):\n",
    "#             # For the sake of evolution of the output format,\n",
    "#             # ignore stream messages that don't match the expected format.\n",
    "#             pass\n",
    "#     final_message = {\n",
    "#                     \"id\": message[\"id\"],\n",
    "#                     \"created\": message[\"created\"],\n",
    "#                     \"model\": message[\"model\"],\n",
    "#                     \"tru_content\": \"\".join(full_content),\n",
    "#                     \"usage\": message[\"usage\"]\n",
    "#                 }\n",
    "#     return final_message\n",
    "\n",
    "\n",
    "# def _modified_complete_non_streaming_immediate(\n",
    "#     model: str,\n",
    "#     prompt,\n",
    "#     options,\n",
    "#     session: Optional[Union[str, Session]] = None,\n",
    "#     deadline: Optional[float] = None,\n",
    "# ) -> str:\n",
    "#     response = _complete._complete_rest(model=model, prompt=prompt, options=options, session=session, deadline=deadline)\n",
    "#     return response\n",
    "\n",
    "# _complete._return_stream_response = _patched_return_stream_response\n",
    "\n",
    "# _complete._complete_non_streaming_immediate = _modified_complete_non_streaming_immediate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from snowflake.cortex import Complete\n",
    "\n",
    "# res_str = Complete(model='mistral-7b', prompt=[{'role': 'user', 'content': 'what is 2 + 2'}], session=snowflake_session)\n",
    "# res_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up feedback functions.\n",
    "\n",
    "Here we'll use groundedness, answer relevance and context relevance to detect hallucination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import snowflake.connector\n",
    "from trulens.core import Feedback\n",
    "from trulens.core import Select\n",
    "from trulens.providers.cortex import Cortex\n",
    "\n",
    "# Create a Snowflake connection\n",
    "snowflake_connection = snowflake.connector.connect(\n",
    "    **connection_params\n",
    ")\n",
    "provider = Cortex(\n",
    "    snowflake_connection,\n",
    "    model_engine=\"snowflake-arctic\",\n",
    ")\n",
    "\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "# f_groundedness = (\n",
    "#     Feedback(\n",
    "#         provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\"\n",
    "#     )\n",
    "#     .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "#     .on_output()\n",
    "# )\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "# f_answer_relevance = (\n",
    "#     Feedback(provider.relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
    "#     .on(Select.RecordCalls.retrieve.args.query)\n",
    "#     .on_output()\n",
    "# )\n",
    "\n",
    "# # Question/statement relevance between question and each context chunk.\n",
    "# f_context_relevance = (\n",
    "#     Feedback(\n",
    "#         provider.context_relevance_with_cot_reasons, name=\"Context Relevance\"\n",
    "#     )\n",
    "#     .on(Select.RecordCalls.retrieve.args.query)\n",
    "#     .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "#     .aggregate(np.mean)\n",
    "# )\n",
    "\n",
    "f_coherence = Feedback(\n",
    "    provider.coherence_with_cot_reasons, name=\"coherence\"\n",
    ").on_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the app\n",
    "Wrap the custom RAG with TruCustomApp, add list of feedbacks for eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.custom import TruCustomApp\n",
    "\n",
    "tru_rag = TruCustomApp(\n",
    "    rag,\n",
    "    app_name=\"RAG\",\n",
    "    app_version=\"v0\",\n",
    "    feedbacks=[\n",
    "        # f_groundedness,\n",
    "        # f_answer_relevance,\n",
    "        # f_context_relevance,\n",
    "        f_coherence,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the app\n",
    "Use `tru_rag` as a context manager for the custom RAG-from-scratch app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_rag as recording:\n",
    "    resp = rag.query(\"When is University of Washington founded?\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "run_dashboard(session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trulens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
